{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a9294ab-1525-467a-8e49-34929109ef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>ok 154 408 768 27 51 AT A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>ok 154 507 766 213 48 NN MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>ok 154 796 764 70 50 TO to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>ok 154 919 757 166 78 VB stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-00-04</td>\n",
       "      <td>ok 154 1185 754 126 61 NPT Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44560</th>\n",
       "      <td>e07-072-09-00</td>\n",
       "      <td>k 156 367 2346 337 75 VBN obtained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44561</th>\n",
       "      <td>e07-072-09-01</td>\n",
       "      <td>k 156 759 2367 89 53 IN at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44562</th>\n",
       "      <td>e07-072-09-02</td>\n",
       "      <td>k 156 891 2389 47 39 AT a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44563</th>\n",
       "      <td>e07-072-09-03</td>\n",
       "      <td>k 156 1022 2351 435 97 JJ comparable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44564</th>\n",
       "      <td>e07-072-09-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44565 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name                                  text\n",
       "0      a01-000u-00-00             ok 154 408 768 27 51 AT A\n",
       "1      a01-000u-00-01         ok 154 507 766 213 48 NN MOVE\n",
       "2      a01-000u-00-02            ok 154 796 764 70 50 TO to\n",
       "3      a01-000u-00-03         ok 154 919 757 166 78 VB stop\n",
       "4      a01-000u-00-04        ok 154 1185 754 126 61 NPT Mr.\n",
       "...               ...                                   ...\n",
       "44560   e07-072-09-00    k 156 367 2346 337 75 VBN obtained\n",
       "44561   e07-072-09-01            k 156 759 2367 89 53 IN at\n",
       "44562   e07-072-09-02             k 156 891 2389 47 39 AT a\n",
       "44563   e07-072-09-03  k 156 1022 2351 435 97 JJ comparable\n",
       "44564     e07-072-09-                                   NaN\n",
       "\n",
       "[44565 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_fwf('/home/shadow04/Downloads/iam_words/words.txt', header=None)\n",
    "df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79460083-5e07-4c8a-9150-64686f91761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a01-000u-00-00</td>\n",
       "      <td>ok 154 408 768 27 51 AT A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-000u-00-01</td>\n",
       "      <td>ok 154 507 766 213 48 NN MOVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-000u-00-02</td>\n",
       "      <td>ok 154 796 764 70 50 TO to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01-000u-00-03</td>\n",
       "      <td>ok 154 919 757 166 78 VB stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a01-000u-00-04</td>\n",
       "      <td>ok 154 1185 754 126 61 NPT Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name                            text\n",
       "0  a01-000u-00-00       ok 154 408 768 27 51 AT A\n",
       "1  a01-000u-00-01   ok 154 507 766 213 48 NN MOVE\n",
       "2  a01-000u-00-02      ok 154 796 764 70 50 TO to\n",
       "3  a01-000u-00-03   ok 154 919 757 166 78 VB stop\n",
       "4  a01-000u-00-04  ok 154 1185 754 126 61 NPT Mr."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some file names end with jp instead of jpg, let's fix this\n",
    "df['file_name'] = df['file_name'].apply(lambda x: x + 'g' if x.endswith('jp') else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "848f9b5c-fa0c-425e-a0f5-03c63be56992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97655639-19fb-4a02-a0e5-f92a588ba68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b03-109-00-07</td>\n",
       "      <td>k 191 1511 731 169 90 NN scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b03-092-03-05</td>\n",
       "      <td>k 152 1119 1277 113 80 NN fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d04-032-03-02</td>\n",
       "      <td>rr 183 855 1273 196 146 JJ human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a06-134-06-02</td>\n",
       "      <td>rr 178 728 2007 83 38 , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c04-160-01-05</td>\n",
       "      <td>k 173 1636 946 193 68 NN viewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>a05-069-07-02</td>\n",
       "      <td>k 175 952 2038 21 46 ; ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>b04-116-03-11</td>\n",
       "      <td>k 162 2225 1339 5 6 . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>a01-020x-07-02</td>\n",
       "      <td>ok 153 751 2150 89 74 ATI the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>a01-128-01-00</td>\n",
       "      <td>k 160 350 959 38 44 AT a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>c03-000b-01-01</td>\n",
       "      <td>ok 152 500 946 92 104 INO of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name                              text\n",
       "0      b03-109-00-07    k 191 1511 731 169 90 NN scale\n",
       "1      b03-092-03-05   k 152 1119 1277 113 80 NN fight\n",
       "2      d04-032-03-02  rr 183 855 1273 196 146 JJ human\n",
       "3      a06-134-06-02         rr 178 728 2007 83 38 , ,\n",
       "4      c04-160-01-05   k 173 1636 946 193 68 NN viewer\n",
       "...              ...                               ...\n",
       "8908   a05-069-07-02          k 175 952 2038 21 46 ; ;\n",
       "8909   b04-116-03-11           k 162 2225 1339 5 6 . .\n",
       "8910  a01-020x-07-02     ok 153 751 2150 89 74 ATI the\n",
       "8911   a01-128-01-00          k 160 350 959 38 44 AT a\n",
       "8912  c03-000b-01-01      ok 152 500 946 92 104 INO of\n",
       "\n",
       "[8913 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "# we reset the indices to start from zero\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "172cd8eb-b6e3-4d92-b986-cc2f7eeeed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]  # e.g., 'a03-017-04-02'\n",
    "        subfolder1 = file_name[:3]            # 'a03'\n",
    "        subfolder2 = file_name.rsplit('-', 2)[0]  # 'a03-017'\n",
    "        \n",
    "        file_path = os.path.join(self.root_dir, subfolder1, subfolder2, file_name + '.png')\n",
    "        image = Image.open(file_path).convert(\"RGB\")\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        \n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad824975-1581-4581-af48-96bf3c2d7ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c01-014-05-04</td>\n",
       "      <td>k 189 1765 1804 88 138 IN31 by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a01-128-06-10</td>\n",
       "      <td>k 160 1887 1835 110 68 ATI the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a01-063-07-05</td>\n",
       "      <td>k 152 1812 1961 94 99 IN to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a02-086-03-10</td>\n",
       "      <td>k 172 1900 1259 145 85 CS that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e01-119-01-03</td>\n",
       "      <td>k 162 960 1080 104 126 JJ long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>a01-020-02-03</td>\n",
       "      <td>k 176 744 1273 70 63 PP3A He</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>c06-080-03-00</td>\n",
       "      <td>k 173 321 1462 263 81 NN touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>e01-102-07-03</td>\n",
       "      <td>k 180 1115 2024 54 63 IN in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>c03-084a-05-06</td>\n",
       "      <td>ok 185 1289 1671 197 69 NP Ferris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>a04-015-06-03</td>\n",
       "      <td>k 172 1136 1998 249 102 NN expansion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name                                  text\n",
       "0      c01-014-05-04        k 189 1765 1804 88 138 IN31 by\n",
       "1      a01-128-06-10        k 160 1887 1835 110 68 ATI the\n",
       "2      a01-063-07-05           k 152 1812 1961 94 99 IN to\n",
       "3      a02-086-03-10        k 172 1900 1259 145 85 CS that\n",
       "4      e01-119-01-03        k 162 960 1080 104 126 JJ long\n",
       "...              ...                                   ...\n",
       "8908   a01-020-02-03          k 176 744 1273 70 63 PP3A He\n",
       "8909   c06-080-03-00        k 173 321 1462 263 81 NN touch\n",
       "8910   e01-102-07-03           k 180 1115 2024 54 63 IN in\n",
       "8911  c03-084a-05-06     ok 185 1289 1671 197 69 NP Ferris\n",
       "8912   a04-015-06-03  k 172 1136 1998 249 102 NN expansion\n",
       "\n",
       "[8913 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1595b331-6eb0-4461-88d6-25bc495d26ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k</td>\n",
       "      <td>182</td>\n",
       "      <td>727</td>\n",
       "      <td>2185</td>\n",
       "      <td>167</td>\n",
       "      <td>113</td>\n",
       "      <td>IN</td>\n",
       "      <td>from</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok</td>\n",
       "      <td>170</td>\n",
       "      <td>1448</td>\n",
       "      <td>2179</td>\n",
       "      <td>164</td>\n",
       "      <td>57</td>\n",
       "      <td>NNS</td>\n",
       "      <td>bills</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k</td>\n",
       "      <td>175</td>\n",
       "      <td>2086</td>\n",
       "      <td>1284</td>\n",
       "      <td>227</td>\n",
       "      <td>58</td>\n",
       "      <td>NN</td>\n",
       "      <td>word</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>err</td>\n",
       "      <td>177</td>\n",
       "      <td>1231</td>\n",
       "      <td>1251</td>\n",
       "      <td>318</td>\n",
       "      <td>81</td>\n",
       "      <td>NN</td>\n",
       "      <td>resolution</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok</td>\n",
       "      <td>171</td>\n",
       "      <td>347</td>\n",
       "      <td>2229</td>\n",
       "      <td>140</td>\n",
       "      <td>40</td>\n",
       "      <td>ATI</td>\n",
       "      <td>the</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>ok</td>\n",
       "      <td>172</td>\n",
       "      <td>1771</td>\n",
       "      <td>1061</td>\n",
       "      <td>291</td>\n",
       "      <td>71</td>\n",
       "      <td>NN</td>\n",
       "      <td>cinema</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>rr</td>\n",
       "      <td>165</td>\n",
       "      <td>2126</td>\n",
       "      <td>1728</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>k</td>\n",
       "      <td>182</td>\n",
       "      <td>1506</td>\n",
       "      <td>759</td>\n",
       "      <td>147</td>\n",
       "      <td>80</td>\n",
       "      <td>CC</td>\n",
       "      <td>But</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>k</td>\n",
       "      <td>176</td>\n",
       "      <td>617</td>\n",
       "      <td>1376</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>BER</td>\n",
       "      <td>are</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>k</td>\n",
       "      <td>182</td>\n",
       "      <td>1944</td>\n",
       "      <td>1785</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8913 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1     2     3    4    5    6           7     8     9\n",
       "0       k  182   727  2185  167  113   IN        from  None  None\n",
       "1      ok  170  1448  2179  164   57  NNS       bills  None  None\n",
       "2       k  175  2086  1284  227   58   NN        word  None  None\n",
       "3     err  177  1231  1251  318   81   NN  resolution  None  None\n",
       "4      ok  171   347  2229  140   40  ATI         the  None  None\n",
       "...   ...  ...   ...   ...  ...  ...  ...         ...   ...   ...\n",
       "8908   ok  172  1771  1061  291   71   NN      cinema  None  None\n",
       "8909   rr  165  2126  1728    9   12    .           .  None  None\n",
       "8910    k  182  1506   759  147   80   CC         But  None  None\n",
       "8911    k  176   617  1376   84   38  BER         are  None  None\n",
       "8912    k  182  1944  1785   66   74   IN          in  None  None\n",
       "\n",
       "[8913 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=test_df.file_name\n",
    "split_df = test_df.text.str.split(' ', expand=True)\n",
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b156db13-fb93-4247-a4c2-e51b6dfbdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "train_dataset = IAMDataset(root_dir='/home/shadow04/Downloads/iam_words/words/',\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = IAMDataset(root_dir='/home/shadow04/Downloads/iam_words/words/',\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "860d5537-152e-4f68-99f6-074e084d0a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_values': tensor([[[0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [0.9686, 0.9686, 0.9686,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]), 'labels': tensor([    0,   330, 17235,   195,  4280,   501,  4390, 11571,  1510, 18390,\n",
      "         1629,   832,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])}\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e27982d-25de-4c82-8349-2669dd714419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 35652\n",
      "Number of validation examples: 8913\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3480a0e4-8b79-430c-a33a-1a3f539190f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 384, 384])\n",
      "labels torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c8913b4-f8b6-4282-b60f-69fc35400fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=252x59>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = train_dataset.df['file_name'][1]  # e.g., 'a03-017-04-02'\n",
    "subfolder1 = file_name[:3]            # 'a03'\n",
    "subfolder2 = file_name.rsplit('-', 2)[0]  # 'a03-017'\n",
    "\n",
    "file_path = os.path.join(train_dataset.root_dir, subfolder1, subfolder2, file_name + '.png')\n",
    "image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "#image = Image.open(train_dataset.root_dir + train_df['file_name'][0]).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47ad0f13-f2fc-4c2e-95d9-5e15cebd0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 190 566 1457 111 70 PP$ His\n"
     ]
    }
   ],
   "source": [
    "labels = encoding['labels']\n",
    "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aed280e7-5866-4397-9499-c7f883020d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at /home/shadow04/Downloads/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"/home/shadow04/Downloads/trocr-small-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e45e6839-16e6-4105-b5ca-2d8b2cb0743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ac62ad0-9d99-4c94-baea-45b46b8198b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    fp16=True, \n",
    "    output_dir=\"./\",\n",
    "    logging_steps=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=200,\n",
    "    \n",
    ")\n",
    "#    evaluation_strategy=\"steps\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb32b5bc-0987-463a-8d79-1caa9acef545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "657aeaa7-08e9-4086-8909-084553d3efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd6ab792-d30e-479f-9b0e-29f797708aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62600/1874935234.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43' max='13371' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   43/13371 02:42 < 14:41:54, 0.25 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.642200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.511400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.546700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.508300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>7.320900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>7.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>7.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>7.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>7.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>7.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>7.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>7.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>7.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>7.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>7.147100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>7.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.862000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The channel dimension is ambiguous. Got image shape (1, 1, 3). Assuming channels are the first dimension. Use the [input_data_format](https://huggingface.co/docs/transformers/main/internal/image_processing_utils#transformers.image_transforms.rescale.input_data_format) parameter to assign the channel dimension.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mean must have 1 elements if it is an iterable, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[101]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# instantiate trainer\u001b[39;00m\n\u001b[32m      4\u001b[39m trainer = Seq2SeqTrainer(\n\u001b[32m      5\u001b[39m     model=model,\n\u001b[32m      6\u001b[39m     tokenizer=processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     data_collator=default_data_collator,\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[32m   2241\u001b[39m         args=args,\n\u001b[32m   2242\u001b[39m         resume_from_checkpoint=resume_from_checkpoint,\n\u001b[32m   2243\u001b[39m         trial=trial,\n\u001b[32m   2244\u001b[39m         ignore_keys_for_eval=ignore_keys_for_eval,\n\u001b[32m   2245\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/trainer.py:2509\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2507\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2508\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2509\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28mself\u001b[39m.get_batch_samples(epoch_iterator, num_batches, args.device)\n\u001b[32m   2510\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2511\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/trainer.py:5263\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5262\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5263\u001b[39m         batch_samples.append(\u001b[38;5;28mnext\u001b[39m(epoch_iterator))\n\u001b[32m   5264\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5265\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/accelerate/data_loader.py:577\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    575\u001b[39m     current_batch = send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28mself\u001b[39m._non_blocking)\n\u001b[32m    576\u001b[39m \u001b[38;5;28mself\u001b[39m._update_state_dict()\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m next_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_index >= \u001b[38;5;28mself\u001b[39m.skip_batches:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mIAMDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     24\u001b[39m text = \u001b[38;5;28mself\u001b[39m.df[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][idx]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# prepare image (i.e. resize + normalize)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m pixel_values = \u001b[38;5;28mself\u001b[39m.processor(image, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).pixel_values\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# add labels (input_ids) by encoding the text\u001b[39;00m\n\u001b[32m     28\u001b[39m labels = \u001b[38;5;28mself\u001b[39m.processor.tokenizer(text, \n\u001b[32m     29\u001b[39m                                   padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     30\u001b[39m                                   max_length=\u001b[38;5;28mself\u001b[39m.max_target_length).input_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/models/trocr/processing_trocr.py:100\u001b[39m, in \u001b[36mTrOCRProcessor.__call__\u001b[39m\u001b[34m(self, images, text, audio, videos, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m output_kwargs = \u001b[38;5;28mself\u001b[39m._merge_kwargs(\n\u001b[32m     94\u001b[39m     TrOCRProcessorKwargs,\n\u001b[32m     95\u001b[39m     tokenizer_init_kwargs=\u001b[38;5;28mself\u001b[39m.tokenizer.init_kwargs,\n\u001b[32m     96\u001b[39m     **kwargs,\n\u001b[32m     97\u001b[39m )\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m.image_processor(images, **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33mimages_kwargs\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    102\u001b[39m     encodings = \u001b[38;5;28mself\u001b[39m.tokenizer(text, **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33mtext_kwargs\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/image_processing_utils.py:44\u001b[39m, in \u001b[36mBaseImageProcessor.__call__\u001b[39m\u001b[34m(self, images, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, **kwargs) -> BatchFeature:\n\u001b[32m     43\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.preprocess(images, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/utils/generic.py:870\u001b[39m, in \u001b[36mfilter_out_non_signature_kwargs.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    861\u001b[39m         cls_prefix = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    863\u001b[39m     warnings.warn(\n\u001b[32m    864\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe following named arguments are not valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    865\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m and were ignored: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_kwargs_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    866\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    867\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    868\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **valid_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/models/vit/image_processing_vit.py:276\u001b[39m, in \u001b[36mViTImageProcessor.preprocess\u001b[39m\u001b[34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, input_data_format, do_convert_rgb)\u001b[39m\n\u001b[32m    269\u001b[39m     images = [\n\u001b[32m    270\u001b[39m         \u001b[38;5;28mself\u001b[39m.rescale(image=image, scale=rescale_factor, input_data_format=input_data_format)\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[32m    272\u001b[39m     ]\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_normalize:\n\u001b[32m    275\u001b[39m     images = [\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m         \u001b[38;5;28mself\u001b[39m.normalize(image=image, mean=image_mean, std=image_std, input_data_format=input_data_format)\n\u001b[32m    277\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[32m    278\u001b[39m     ]\n\u001b[32m    280\u001b[39m images = [\n\u001b[32m    281\u001b[39m     to_channel_dimension_format(image, data_format, input_channel_dim=input_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[32m    282\u001b[39m ]\n\u001b[32m    284\u001b[39m data = {\u001b[33m\"\u001b[39m\u001b[33mpixel_values\u001b[39m\u001b[33m\"\u001b[39m: images}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/image_processing_utils.py:114\u001b[39m, in \u001b[36mBaseImageProcessor.normalize\u001b[39m\u001b[34m(self, image, mean, std, data_format, input_data_format, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize\u001b[39m(\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     83\u001b[39m     image: np.ndarray,\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m     **kwargs,\n\u001b[32m     89\u001b[39m ) -> np.ndarray:\n\u001b[32m     90\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    Normalize an image. image = (image - image_mean) / image_std.\u001b[39;00m\n\u001b[32m     92\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m        `np.ndarray`: The normalized image.\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m normalize(\n\u001b[32m    115\u001b[39m         image, mean=mean, std=std, data_format=data_format, input_data_format=input_data_format, **kwargs\n\u001b[32m    116\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/handwriting/lib/python3.13/site-packages/transformers/image_transforms.py:433\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(image, mean, std, data_format, input_data_format)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mean, Collection):\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mean) != num_channels:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmean must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements if it is an iterable, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mean)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m     mean = [mean] * num_channels\n",
      "\u001b[31mValueError\u001b[39m: mean must have 1 elements if it is an iterable, got 3"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb41e0-285c-4627-b1d1-b7fd975e0b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
